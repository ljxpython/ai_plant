# AI SQL 准确性：测试不同的 LLMs 和上下文策略以最大化 SQL 生成准确性
_2024-03-08_

## 摘要

拥有一个能够回答业务用户问题的自主 AI 代理的承诺是一个吸引人但迄今为止难以实现的命题。许多人尝试让 ChatGPT 编写 SQL，但成功率有限，主要失败原因是 LLM 对特定数据集的了解不足。

在本文中，**我们展示了上下文的重要性，有了正确的上下文，我们可以实现从约 3% 的准确性到约 80% 的准确性**。我们经历了三种不同的上下文策略，并展示了一个明显的胜者——我们将模式定义、文档和先前的 SQL 查询与相关性搜索结合起来。

我们还比较了几种不同的 LLMs——包括 Google Bison、GPT 3.5、GPT 4、Moonshot，以及对 Llama 2 的简短尝试。虽然 **GPT 4 在生成 SQL 方面总体上是最好的 LLM**，但在提供足够上下文的情况下，Google 的 Bison 表现大致相当。

最后，我们展示了如何使用这里展示的方法为您的数据库生成 SQL。

这是我们主要发现的总结——

![](/img/summary.png)

## 目录
* [为什么使用 AI 生成 SQL？](#为什么使用-ai-生成-sql)
* [设置测试架构](#设置测试架构)
* [设置测试杠杆](#设置测试杠杆)
    * [选择数据集](#选择数据集)
    * [选择问题](#选择问题)
    * [选择提示](#选择提示)
    * [选择 LLMs（基础模型）](#选择-llms-基础模型)
    * [选择上下文](#选择上下文)
* [使用 ChatGPT 生成 SQL](#使用-chatgpt-生成-sql)
* [仅使用模式](#仅使用模式)
* [使用 SQL 示例](#使用-sql-示例)
* [使用上下文相关示例](#使用-上下文相关示例)
* [分析结果](#分析结果)
* [下一步提高准确性](#下一步提高准确性)
* [使用 AI 为您的数据集编写 SQL](#使用-ai-为您的数据集编写-sql)

## 为什么使用 AI 生成 SQL？

许多组织现在已经采用了某种形式的数据仓库或数据湖——这是一个包含组织关键数据的存储库，可以用于分析目的的查询。这片数据海洋充满了潜在的洞察力，但只有企业中一小部分人具备利用数据所需的两项技能——

1. 对 **高级 SQL** 的扎实理解
2. 对 **组织独特数据结构和模式** 的全面了解

同时具备上述两项技能的人数不仅非常少，而且很可能不是那些提出大多数问题的人。

**那么组织内部实际上发生了什么？** 业务用户，如产品经理、销售经理和高管，有数据问题需要回答以指导业务决策和策略。他们首先会检查仪表板，但大多数问题都是特定且临时的，答案并不可用，所以他们会询问数据分析师或工程师——任何具备上述技能组合的人。这些人很忙，需要一段时间才能处理请求，一旦他们得到答案，业务用户就会有跟进问题。

**这个过程对业务用户（长时间等待答案）和分析师（分散主要项目注意力）都是痛苦的**，并导致许多潜在洞察力的丢失。

![](/img/question-flow.png)

**进入生成性 AI！** LLMs 可能为业务用户提供了机会，让他们可以用自然语言查询数据库（LLMs 负责 SQL 翻译），这将改变他们的数据团队甚至整个业务。

**关键挑战是为复杂和混乱的数据库生成准确的 SQL**。我们与许多人交谈过，他们尝试使用 ChatGPT 编写 SQL，但成功率有限，且过程痛苦。许多人已经放弃，回到了手动编写 SQL 的老式方式。最好的情况下，ChatGPT 是分析师获取正确语法的有时有用的副驾驶。

**但有希望！** 我们在过去几个月里深入研究了这个问题，尝试了各种模型、技术和方法来提高 LLMs 生成 SQL 的准确性。在本文中，我们展示了各种 LLMs 的性能，以及向 LLM 提供上下文相关正确 SQL 的策略如何使 LLM 能够 **实现极高的准确性**。

## 设置测试架构

首先，我们需要定义测试的架构。下面是一个粗略的大纲，分为五个步骤，下面是 _伪代码_——

![](/img/test-architecture.png)

1. **问题** - 我们从业务问题开始。
```python
   question = "德国有多少客户"
```
2. **提示** - 我们创建要发送给 LLM 的提示。
```python
   prompt = f"""
   为以下问题编写 SQL 语句：
   {question}
   """
```
3. **生成 SQL** - 使用 API，我们将提示发送给 LLM 并获取生成的 SQL。
```python
   sql = llm.api(api_key=api_key, prompt=prompt, parameters=parameters)
```
4. **运行 SQL** - 我们将 SQL 运行在数据库上。
```python
    df = db.conn.execute(sql)
```
5. **验证结果** - 最后，我们将验证结果是否符合我们的预期。
在结果方面有一些灰色地带，所以我们对结果进行了手动评估。您可以在这里看到这些结果 [这里](/data/sec_evaluation_data_tagged.csv)

## 设置测试杠杆

现在我们已经设置了实验，我们需要弄清楚哪些杠杆会影响准确性，以及我们的测试集是什么。我们尝试了两个杠杆（LLMs 和使用的训练数据），并在构成我们测试集的 20 个问题上运行。所以我们总共运行了 3 LLMs x 3 上下文策略 x 20 个问题 = 180 个单独的试验。

![](/img/test-levers.png)

### 选择数据集

首先，我们需要 **选择一个合适的数据集** 来尝试。我们有几个指导原则——

1. **代表性**。企业中的数据集通常是复杂的，而这种复杂性在许多演示/样本数据集中并没有被捕捉到。我们希望使用一个包含真实世界用例和真实数据的复杂数据库。
2. **可访问性**。我们也希望数据集是公开可用的。
3. **易于理解**。数据集应该对广泛的受众来说在某种程度上是易于理解的——任何过于专业或技术性的内容都将难以解读。
4. **维护**。我们更倾向于选择一个得到适当维护和更新的数据集，以反映真实数据库的情况。

### 选择问题

接下来，我们需要 **选择问题**。这里有一些示例问题（在 ![这个文件](/data/questions_sec.csv) 中查看所有问题）——

1. 数据集中有多少家公司？
2. 'ALPHABET INC.' 收入表中有哪些年度指标可用？
3. 特斯拉的季度“汽车销售”和“汽车租赁”是多少？
4. 目前有多少家 Chipotle 餐厅？

现在我们有了数据集 + 问题，我们需要想出杠杆。

### 选择提示

对于 **提示**，这次我们将保持提示不变，尽管我们会进行后续操作，改变提示。

### 选择 LLMs（基础模型）

对于要测试的 **LLMs**，我们将尝试以下——

1. [**Bison (Google)**](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models) - Bison 是通过 GCP API 可用的 [PaLM 2](https://blog.google/technology/ai/google-palm-2-ai-large-language-model/) 版本。
2. [**GPT 3.5 Turbo (OpenAI)**](https://platform.openai.com/docs/models/gpt-3-5) - 尽管 4 已经可用，但 GPT 3.5 直到最近仍然是 OpenAI 的旗舰模型，因为延迟和成本优势，以及在基本任务上的准确性差异不大（好吧——我们将在测试中验证这一点）。
3. [**GPT 4 (OpenAI)**](https://platform.openai.com/docs/models/gpt-4) - 更先进的但性能稍差的 OpenAI 模型。GPT 4 是多模态的，尽管我们不会使用这个功能。
4. [**Llama 2 (Meta)**](https://ai.meta.com/llama/) - 我们真的很想包括一个开源模型——领先的是 Meta 的 Llama 2。但我们通过 [Replicate](https://replicate.com/replicate/llama-2-70b-chat) 的设置很快就失败了，我们没能及时修复它以发布本文。在我们的早期运行中，当它工作时，我们发现性能充其量是平庸的。

### 选择上下文

最后，我们将有三种类型的 **上下文**。上下文指的是我们发送给 LLM 的信息，帮助 LLM 了解我们特定数据集的上下文。

1. **仅模式**。我们将模式（使用 DDL）放入上下文窗口。
2. **静态示例**。我们将静态示例 SQL 查询放入上下文窗口。
3. **上下文相关示例**。最后，我们将最相关的上下文（SQL/DDL/文档）通过基于嵌入的向量搜索找到并放入上下文窗口。

## 使用 ChatGPT 生成 SQL

这一部分对 ChatGPT 有点不公平，但它是一个很好的起点。让我们只拿一个问题，让 ChatGPT 生成 SQL——

**提示**

```
编写 Snowflake SQL 来回答以下问题 -

Alphabet 的季度收入按业务部门是多少？

只返回 SQL
```

**响应**

当然，这是 SQL 查询：

```sql
SELECT
  EXTRACT(QUARTER FROM date_column) AS quarter,
  business_segment,
  SUM(revenue) AS quarterly_revenue
FROM
  revenue_table
WHERE
  company_name = 'Alphabet'
GROUP BY
  quarter,
  business_segment
ORDER BY
  quarter,
  business_segment;

-- 替换 date_column、business_segment、revenue、revenue_table，并根据您特定的数据库模式调整任何其他标识符。
```

不可避免地，当我们尝试运行这个时，我们会碰到错误，因为它编造了表名，因为我们没有提供它——

![](/img/sql-error.png)

当然，我们对 LLMs 不公平——尽管它们很神奇，但它们不可能（不幸地？幸运地？）知道我们数据库里有什么——但让我们跳到我们提供更多上下文的测试中。

## 仅使用模式

首先，我们拿到数据集的模式并将其放入上下文窗口。这通常是我们在 ChatGPT 或教程中看到人们所做的。

一个示例提示可能看起来像这样（实际上我们使用了信息模式，因为 Snowflake 的共享工作方式，但这展示了原则）——

```
用户提供一个问题，您提供 SQL。您只以 SQL 代码回应，不提供任何解释。

只回应 SQL 代码。不要回答任何解释——只要代码。

您可以使用以下 DDL 语句作为可能可用表的参考。

CREATE TABLE Table1...

CREATE TABLE Table2...

CREATE TABLE Table3...
```

结果是，用一个词来形容，就是糟糕。在 60 次尝试（20 个问题 x 3 个模型）中，只有两个问题被正确回答（都是 GPT 4），**准确率仅为 3%**。以下是 GPT 4 正确回答的两个问题——

1. 最频繁的前 10 个度量描述是什么？
2. 报告属性中有哪些不同的陈述？

![](/img/accuracy-using-schema-only.png)

很明显，仅仅使用模式，我们远远达不到一个有用的 AI SQL 代理的标准，尽管它可能在某种程度上对分析师有所帮助。

## 使用 SQL 示例

如果我们设身处地地想象一个第一次接触这个数据集的人，除了表定义之外，他们首先会查看示例查询，以了解如何正确查询数据库。

这些查询可以提供模式中不可用的其他上下文——例如，使用哪些列，表如何连接在一起，以及查询特定数据集的其他复杂性。

Cybersyn 与其他 Snowflake 市场上的数据提供商一样，在他们的文档中提供了几个（在这个案例中是 3 个）示例查询。让我们将这些包含在上下文窗口中。

仅提供这 3 个示例查询，我们看到生成的 SQL 正确性有了显著提高。然而，这种准确性在不同的基础 LLM 之间有很大差异。看起来 GPT-4 最能够概括示例查询，以生成最准确的 SQL。

![](/img/accuracy-using-static-examples.png)

## 使用上下文相关示例

企业数据仓库通常包含数百（甚至数千）个表，以及覆盖组织内所有用例的查询数量级更多的查询。考虑到现代 LLMs 上下文窗口的有限大小，我们不能仅仅将所有先前的查询和模式定义塞进提示中。

我们对上下文的最终方法是更复杂的 ML 方法——将先前的查询和表模式的嵌入加载到向量数据库中，只选择与所提问题最相关的查询/表。这是我们正在做的事情的图表——注意红色框中的上下文相关搜索——

![](/img/using-contextually-relevant-examples.png)

通过向 LLM 提供最相关的 SQL 查询示例，我们可以显著提高即使是能力较弱的 LLMs 的性能。在这里，我们为问题提供了 10 个最相关的 SQL 查询示例（从存储的 30 个示例列表中），准确率飙升。

![](/img/accuracy-using-contextual-examples.png)

我们可以通过维护一个可执行且正确回答用户实际问题的 SQL 语句历史记录来进一步提高性能。

## 分析结果

很明显，最大的区别不在于 LLM 的类型，而在于为 LLM 提供适当上下文的策略（例如使用的“训练数据”）。

![](/img/summary-table.png)

当查看按上下文策略的 SQL 准确性时，很明显这是产生差异的因素。我们从仅使用模式的约 3% 准确率，到智能使用上下文示例时的约 80% 准确率。

![](/img/summary.png)

LLMs 本身仍有有趣的趋势。虽然 Bison 在模式和静态上下文策略中都处于最底层，但在完整的上下文策略中，它一跃成为顶尖。在三种策略的平均值中，**GPT 4 是 SQL 生成的最佳 LLM**。

![](/img/accuracy-by-llm.png)

## 提高准确性的下一步

我们很快会对这个分析进行跟进，以更深入地了解准确的 SQL 生成。一些下一步是——

1. **使用其他数据集**：我们很想在其他真实世界的企业数据集上尝试这个。当你有 100 个表时会发生什么？1000 个表呢？
2. **增加更多训练数据**：虽然 30 个查询很棒，但当你将这个数字增加 10 倍、100 倍时会发生什么？
3. **尝试更多数据库**：这个测试是在 Snowflake 数据库上运行的，但我们也已经在 BigQuery、Postgres、Redshift 和 SQL Server 上实现了这个功能。
4. **尝试更多基础模型**：我们即将能够使用 Llama 2，我们很想尝试其他 LLMs。

我们有一些关于上述内容的轶事证据，但我们将扩展和完善我们的测试，以包括更多这些项目。

## 使用 AI 为您的数据集编写 SQL

虽然 SEC 数据是一个很好的开始，但您一定想知道这是否与您的数据和您的组织相关。我们正在构建一个 Python 包，它可以为您的数据库生成 SQL，以及额外的功能，如能够生成 Plotly 代码用于图表、跟进问题和各种其他功能。

以下是它的工作原理概述
```python
import DQuestionChat as dq
```

1. **使用模式进行训练**

```python
dq.train(ddl="CREATE TABLE ...")
```

2. **使用文档进行训练**

```python
dq.train(documentation="...")
```

3. **使用 SQL 示例进行训练**

```python
dq.train(sql="SELECT ...")
```

4. **生成 SQL**

DQuestion 最简单的使用方式是 `dq.ask(question="What are the ...")`，它将返回 SQL、表格和图表，`dq.ask` 是 `dq.generate_sql`、`dq.run_sql`、`dq.generate_plotly_code`、`dq.get_plotly_figure` 和 `dq.generate_followup_questions` 的包装器。这将使用优化的上下文为您的问题生成 SQL，DQuestion 将为您调用 LLM。

或者，您可以使用 `dq.get_related_training_data(question="What are the ...")`，它将检索您可以用于构建自己的提示以发送给任何 LLM 的最相关上下文。

## 名词解释

* **基础模型**：这是底层的 LLM。
* **上下文模型（也称为 DQuestion 模型）**：这是位于 LLM 之上的一层，为 LLM 提供上下文。
* **训练**：通常当我们提到“训练”时，我们指的是训练上下文模型。
